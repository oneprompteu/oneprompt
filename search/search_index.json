{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"oneprompt","text":"<p>AI agents for data querying, analysis, and chart generation.</p> <p>Connect your Gemini API key and PostgreSQL database \u2014 query data in natural language, run Python analysis, and generate interactive charts in minutes.</p>"},{"location":"#what-is-oneprompt","title":"What is oneprompt?","text":"<p>oneprompt is a Python SDK that turns natural language into SQL queries, Python analysis scripts, and interactive charts. It supports multiple LLM providers (Google Gemini, OpenAI, Anthropic) and runs tool execution in isolated Docker containers via the Model Context Protocol (MCP).</p> <pre><code>import oneprompt as op\n\nclient = op.Client()\n\n# Ask a question about your data\nresult = client.query(\"What are the top 10 products by revenue?\")\nprint(result.summary)\nprint(result.preview)\n\n# Generate a chart\nchart = client.chart(\"Bar chart of top products\", data_from=result)\nchart.artifacts[0].download(\"./output/\")   # save locally\n\n# Run Python analysis\nstats = client.analyze(\"Calculate month-over-month growth\", data_from=result)\nprint(stats.summary)\n</code></pre>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>\ud83d\udde3\ufe0f Natural language queries \u2014 Ask questions about your PostgreSQL database in plain English</li> <li>\ud83d\udcca Interactive charts \u2014 Generate AntV (G2Plot) visualizations as HTML files</li> <li>\ud83d\udc0d Python analysis \u2014 Run data analysis in a sandboxed environment</li> <li>\ud83d\udd17 Agent chaining \u2014 Pipe results from one agent to another (<code>query \u2192 analyze \u2192 chart</code>)</li> <li>\ud83d\udc33 Docker-based isolation \u2014 All code execution runs in secure containers</li> <li>\ud83d\udda5\ufe0f REST API \u2014 Integrate with any language via HTTP endpoints</li> <li>\u26a1 CLI tooling \u2014 Scaffold, start, stop, and manage everything from the terminal</li> </ul>"},{"location":"#how-it-works","title":"How It Works","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Your App / SDK Client / REST API           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  AI Agents (Gemini + LangChain)             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502   Data   \u2502 \u2502  Python  \u2502 \u2502  Chart   \u2502    \u2502\n\u2502  \u2502  Agent   \u2502 \u2502  Agent   \u2502 \u2502  Agent   \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  MCP Servers (Docker)                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502 Postgres \u2502 \u2502  Python  \u2502 \u2502  Chart   \u2502    \u2502\n\u2502  \u2502   MCP    \u2502 \u2502   MCP    \u2502 \u2502   MCP    \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Artifact Store (generated file storage)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li> <p> Getting Started</p> <p>Install the SDK and run your first query in 5 minutes.</p> <p> Quick Start</p> </li> <li> <p> Guides</p> <p>Learn how to configure your project, document your schema, and chain agents.</p> <p> Guides</p> </li> <li> <p> API Reference</p> <p>Complete reference for the Python SDK, REST API, and CLI.</p> <p> Reference</p> </li> <li> <p> Architecture</p> <p>Understand how components, MCP servers, and data flow work together.</p> <p> Architecture</p> </li> </ul>"},{"location":"architecture/overview/","title":"Architecture Overview","text":"<p>Technical documentation of the oneprompt system architecture.</p>"},{"location":"architecture/overview/#overview","title":"Overview","text":"<p>oneprompt is built as a local-first SDK that orchestrates AI agents via Docker-based MCP servers. The system runs entirely on your machine \u2014 no cloud services, no external APIs beyond the Gemini LLM.</p> <pre><code>Your Application\n  \u251c\u2500\u2500 Python SDK (op.Client)     or     REST API (op api)\n  \u2502\n  \u25bc\nAI Agents (Gemini + LangChain)\n  \u251c\u2500\u2500 Data Agent \u2500\u2500\u2500\u2500 PostgreSQL MCP (:3333) \u2500\u2500\u2500\u2500 Your PostgreSQL DB\n  \u251c\u2500\u2500 Python Agent \u2500\u2500 Python MCP (:3335)\n  \u2514\u2500\u2500 Chart Agent \u2500\u2500\u2500 Chart MCP (:3334)\n                         \u2502\n                   Artifact Store (:3336)\n                   (shared file storage)\n</code></pre>"},{"location":"architecture/overview/#components","title":"Components","text":""},{"location":"architecture/overview/#python-sdk","title":"Python SDK","text":"<p>The <code>Client</code> class is the main entry point. It handles:</p> <ul> <li>Configuration loading (<code>.env</code>, environment variables, or explicit args)</li> <li>Session and run management via local SQLite</li> <li>Agent orchestration (calling the correct agent for each method)</li> <li>On-demand artifact access via the Artifact Store</li> </ul> File Purpose <code>client.py</code> <code>Client</code> class with <code>query()</code>, <code>chart()</code>, <code>analyze()</code> <code>config.py</code> <code>Config</code> dataclass with all settings <code>cli.py</code> CLI commands (<code>op init</code>, <code>op start</code>, etc.) <code>api.py</code> FastAPI REST API server"},{"location":"architecture/overview/#ai-agents","title":"AI Agents","text":"<p>Each agent is a LangChain agent powered by Google Gemini that connects to a specific MCP server:</p> Agent MCP Server Purpose Data Agent PostgreSQL MCP Translate natural language \u2192 SQL, execute, export results Python Agent Python MCP Execute Python analysis code in a sandbox Chart Agent Chart MCP Generate interactive AntV (G2Plot) charts <p>Each agent:</p> <ol> <li>Connects to its MCP server via HTTP</li> <li>Loads available tools from the MCP server</li> <li>Uses Gemini to reason about the request and call the appropriate tools</li> <li>Returns a structured JSON response with results and artifacts</li> </ol>"},{"location":"architecture/overview/#postgresql-mcp-server","title":"PostgreSQL MCP Server","text":"<p>Port: 3333 \u00b7 Framework: FastMCP</p> Tool Description <code>query_preview</code> Execute SQL and return first rows <code>export_query</code> Execute SQL and export to CSV/JSON <code>get_tables</code> List available tables <p>The dataset connection is passed dynamically via HTTP headers. When <code>DATASET_TOKEN_SECRET</code> is configured, the Data Agent sends an encrypted <code>x-dataset-token</code> instead of plaintext DSN.</p>"},{"location":"architecture/overview/#python-mcp-server","title":"Python MCP Server","text":"<p>Port: 3335 \u00b7 Framework: FastMCP</p> Tool Description <code>run_python</code> Execute Python code in a secure subprocess <p>The sandbox runs with restricted permissions:</p> <ul> <li>Read-only filesystem</li> <li>Limited memory (2GB) and CPU (2 cores)</li> <li>No network access from within the sandbox</li> <li>Temporary files only in <code>/tmp</code></li> </ul>"},{"location":"architecture/overview/#chart-mcp-server","title":"Chart MCP Server","text":"<p>Port: 3334 \u00b7 Framework: FastMCP</p> Tool Description <code>generate_chart</code> Create an HTML file with an AntV G2Plot chart <p>Supports bar, line, pie, scatter, area, and other chart types.</p>"},{"location":"architecture/overview/#artifact-store","title":"Artifact Store","text":"<p>Port: 3336 \u00b7 Framework: FastAPI</p> <p>A simple file storage service:</p> <ul> <li>PUT \u2014 Upload generated files (CSV, JSON, HTML)</li> <li>GET \u2014 Download files by path</li> </ul> <p>Files are organized by session and run:</p> <pre><code>exports/\n  {session_id}/\n    runs/\n      {run_id}/\n        data/       \u2190 Data Agent outputs (CSV, JSON)\n        results/    \u2190 Python Agent outputs\n        charts/     \u2190 Chart Agent outputs (HTML)\n</code></pre>"},{"location":"architecture/overview/#state-store-sqlite","title":"State Store (SQLite)","text":"<p>Local SQLite database for metadata, stored at <code>op_data/state.db</code>:</p> Table Contents <code>sessions</code> Session ID, name, status, timestamps <code>runs</code> Run ID, session ID, status, timestamps <code>artifacts</code> Artifact ID, run ID, session ID, filename, store path"},{"location":"architecture/overview/#data-flow","title":"Data Flow","text":""},{"location":"architecture/overview/#single-query","title":"Single Query","text":"<pre><code>1. Client.query(\"Top 10 products by revenue\")\n   \u251c\u2500\u2500 Creates session (if needed)\n   \u251c\u2500\u2500 Generates unique run_id\n   \u2514\u2500\u2500 Calls Data Agent\n\n2. Data Agent\n   \u251c\u2500\u2500 Connects to PostgreSQL MCP via HTTP\n   \u251c\u2500\u2500 Passes DATABASE.md schema as context to Gemini\n   \u251c\u2500\u2500 Gemini generates SQL query\n   \u2514\u2500\u2500 Calls MCP tool: export_query(sql=\"SELECT ...\")\n\n3. PostgreSQL MCP\n   \u251c\u2500\u2500 Connects to your PostgreSQL database\n   \u251c\u2500\u2500 Executes the SQL query\n   \u251c\u2500\u2500 Exports results to CSV + JSON\n   \u2514\u2500\u2500 Stores files in Artifact Store\n\n4. Client\n   \u251c\u2500\u2500 Creates ArtifactRef objects with remote URLs\n   \u251c\u2500\u2500 Artifacts are fetched on-demand via read_text() or download()\n   \u2514\u2500\u2500 Returns AgentResult to your code\n</code></pre>"},{"location":"architecture/overview/#chained-workflow","title":"Chained Workflow","text":"<pre><code>query(\"Revenue by month\")\n  \u2514\u2500\u2500 AgentResult with CSV/JSON artifacts\n        \u2502  passed via data_from parameter\n        \u25bc\nanalyze(\"Calculate growth rate\", data_from=result)\n  \u2514\u2500\u2500 Reads JSON data from artifact (fetched on-demand)\n        \u2502  passed via data_from parameter\n        \u25bc\nchart(\"Line chart of growth\", data_from=analysis)\n  \u2514\u2500\u2500 Reads JSON data from artifact (fetched on-demand)\n  \u2514\u2500\u2500 Returns HTML chart artifact\n</code></pre>"},{"location":"architecture/overview/#mcp-model-context-protocol","title":"MCP (Model Context Protocol)","text":""},{"location":"architecture/overview/#what-is-mcp","title":"What is MCP?","text":"<p>MCP is an open protocol for connecting LLMs to external tools in a standardized way. Each MCP server exposes:</p> <ul> <li>Tools \u2014 Functions the LLM can call (e.g. <code>export_query</code>, <code>run_python</code>)</li> <li>Prompts \u2014 Contextual information for the LLM</li> <li>Resources \u2014 Static content (e.g. database schema documentation)</li> </ul>"},{"location":"architecture/overview/#why-mcp","title":"Why MCP?","text":"<ol> <li>Separation of concerns \u2014 Each server handles one domain (SQL, Python, Charts)</li> <li>Security \u2014 Code execution is isolated in Docker containers</li> <li>Scalability \u2014 Servers are stateless and independently deployable</li> <li>Reusability \u2014 The same MCP server can serve multiple agents</li> </ol>"},{"location":"architecture/overview/#agent-mcp-connection","title":"Agent \u2192 MCP Connection","text":"<pre><code># Simplified from agents/data_agent.py\nfrom langchain_mcp_adapters.client import MultiServerMCPClient\n\nclient = MultiServerMCPClient({\n    \"postgres\": {\n        \"transport\": \"http\",\n        \"url\": \"http://localhost:3333/mcp\",\n        \"headers\": {\n            \"mcp-session-id\": \"session_abc\",\n            \"mcp-run-id\": \"run_xyz\",\n            \"x-dataset-token\": \"&lt;encrypted-token&gt;\",\n        }\n    }\n})\n\nasync with client.session(\"postgres\") as session:\n    tools = await load_mcp_tools(session)\n    agent = create_agent(gemini_llm, tools)\n    result = await agent.run(\"Top 10 products by revenue\")\n</code></pre>"},{"location":"architecture/overview/#local-storage","title":"Local Storage","text":"<p>All local data is stored under <code>op_data/</code> (configurable via <code>OP_DATA_DIR</code>):</p> <pre><code>op_data/\n  \u251c\u2500\u2500 state.db          \u2190 SQLite: sessions, runs, artifacts metadata\n  \u251c\u2500\u2500 .artifact_token   \u2190 Auto-generated auth token for Artifact Store\n  \u2514\u2500\u2500 exports/          \u2190 Shared Docker volume for artifact files\n      \u2514\u2500\u2500 {session_id}/\n          \u2514\u2500\u2500 runs/\n              \u2514\u2500\u2500 {run_id}/\n                  \u251c\u2500\u2500 data/\n                  \u251c\u2500\u2500 results/\n                  \u2514\u2500\u2500 charts/\n</code></pre> <p>Artifacts are stored in the Artifact Store (Docker container). Use <code>artifact.read_text()</code> to fetch content on demand, or <code>artifact.download(\"./output/\")</code> to save locally.</p>"},{"location":"architecture/overview/#docker-services","title":"Docker Services","text":"<p>All MCP servers and the Artifact Store run as Docker containers managed by Docker Compose.</p>"},{"location":"architecture/overview/#services","title":"Services","text":"Service Dockerfile Port Purpose <code>artifact-store</code> <code>Dockerfile.artifact-store</code> 3336 File storage <code>postgres-mcp</code> <code>Dockerfile.postgres</code> 3333 SQL query engine <code>chart-mcp</code> <code>Dockerfile.chart</code> 3334 Chart generation <code>python-mcp</code> <code>Dockerfile.python</code> 3335 Sandboxed Python"},{"location":"architecture/overview/#shared-volume","title":"Shared Volume","text":"<p>All services share a Docker volume (<code>op_exports</code>) mounted at <code>/app/exports</code>. This allows:</p> <ul> <li>MCP servers to write output files</li> <li>Artifact Store to serve those files via HTTP</li> <li>Files to persist across container restarts</li> </ul>"},{"location":"architecture/overview/#security","title":"Security","text":"<p>The Python MCP runs with hardened settings:</p> <pre><code>read_only: true\ntmpfs: /tmp:size=100M\nsecurity_opt: [no-new-privileges:true]\ncap_drop: [ALL]\nresources:\n  limits:\n    memory: 2G\n    cpus: \"2\"\n</code></pre>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.12 or higher</li> <li>oneprompt API key for cloud mode (<code>ONEPROMPT_API_KEY</code>)</li> <li>Docker \u2014 only required for local/full mode (Get Docker)</li> </ul>"},{"location":"getting-started/installation/#install-the-sdk","title":"Install the SDK","text":""},{"location":"getting-started/installation/#cloud-only-recommended-for-saas","title":"Cloud-only (recommended for SaaS)","text":"<pre><code>pip install oneprompt-sdk\n</code></pre> <p>Use <code>import oneprompt_sdk as op</code> and call the hosted API directly.</p>"},{"location":"getting-started/installation/#full-local-stack","title":"Full local stack","text":"<pre><code>pip install oneprompt\n</code></pre> <p>This installs the <code>oneprompt</code> Python package and the <code>op</code> CLI tool.</p>"},{"location":"getting-started/installation/#verify-installation","title":"Verify installation","text":"<pre><code>op --version\n</code></pre>"},{"location":"getting-started/installation/#what-gets-installed","title":"What gets installed","text":"Component Description <code>oneprompt</code> Full Python SDK package <code>op</code> CLI tool for project management Docker images Built automatically on first <code>op start</code>"},{"location":"getting-started/installation/#next-steps","title":"Next steps","text":"<p>Once installed, follow the Quick Start guide to initialize a project and run your first query.</p>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>Get up and running with oneprompt in 5 minutes.</p> <p>Cloud-only setup</p> <p>For SaaS/cloud usage without Docker, install <code>oneprompt-sdk</code> and use <code>import oneprompt_sdk as op</code>. Use <code>oneprompt</code> + <code>op start</code> only for local/self-hosted MCP workflows.</p>"},{"location":"getting-started/quickstart/#1-initialize-a-project","title":"1. Initialize a project","text":"<pre><code>op init\n</code></pre> <p>When prompted, choose <code>0</code>/<code>local</code> for this local quickstart flow.</p> <p>This creates the following files in your current directory (local mode):</p> File Purpose <code>DATABASE.md</code> Schema documentation template <code>docker-compose.yml</code> Docker stack for MCP servers <code>example.py</code> Ready-to-run example script"},{"location":"getting-started/quickstart/#2-document-your-schema","title":"2. Document your schema","text":"<p>Edit <code>DATABASE.md</code> to describe your tables, columns, and relationships. The more detail you provide, the better the AI will write SQL queries.</p> <pre><code># Database Schema\n\n## Tables\n\n### products\n| Column | Type | Description |\n|--------|------|-------------|\n| id | integer | Primary key |\n| name | text | Product name |\n| price | numeric | Unit price in USD |\n| category | text | Product category |\n\n### orders\n| Column | Type | Description |\n|--------|------|-------------|\n| id | integer | Primary key |\n| product_id | integer | FK \u2192 products.id |\n| quantity | integer | Units ordered |\n| total | numeric | Order total |\n| created_at | timestamp | Order date |\n\n## Relationships\n- products.id \u2192 orders.product_id (one product, many orders)\n</code></pre> <p>See the Schema Documentation Guide for the full recommended format.</p>"},{"location":"getting-started/quickstart/#3-start-services","title":"3. Start services","text":"<pre><code>op start\n</code></pre> <p>This builds and launches 4 Docker containers:</p> Service Port Description Artifact Store 3336 Generated file storage (CSV, JSON, HTML) PostgreSQL MCP 3333 SQL query execution Chart MCP 3334 AntV chart generation Python MCP 3335 Sandboxed Python execution <p>First run</p> <p>The first <code>op start</code> builds Docker images, which may take a few minutes. Subsequent starts are much faster.</p>"},{"location":"getting-started/quickstart/#4-run-your-first-query","title":"4. Run your first query","text":"<p>Configure credentials directly in your script:</p> <pre><code>from oneprompt import Client, Config\n\nconfig = Config(\n    llm_provider=\"google\",       # \"google\", \"openai\", or \"anthropic\"\n    llm_api_key=\"your-api-key\",\n    # If PostgreSQL runs locally, use host.docker.internal (not localhost)\n    database_url=\"postgresql://user:password@host.docker.internal:5432/mydb\",\n    schema_docs_path=\"./DATABASE.md\",\n)\n\nclient = Client(config=config)\n\n# Query your database\nresult = client.query(\"What are the top 10 products by revenue?\")\nprint(result.summary)\nprint(result.preview)\nprint(result.metrics)   # RunMetrics(duration_ms=..., input_tokens=..., output_tokens=...)\n</code></pre> <p>Or run the generated example:</p> <pre><code>python example.py\n</code></pre> <p>Get your API key</p> <ul> <li>Google Gemini: Google AI Studio</li> <li>OpenAI: platform.openai.com</li> <li>Anthropic: console.anthropic.com</li> </ul>"},{"location":"getting-started/quickstart/#5-generate-a-chart","title":"5. Generate a chart","text":"<pre><code># Use the query result as input\nchart = client.chart(\"Bar chart of top products\", data_from=result)\nprint(chart.summary)\n\n# Download the chart and open it in your browser\nfor art in chart.artifacts:\n    art.download(\"./output/\")\n</code></pre>"},{"location":"getting-started/quickstart/#6-run-python-analysis","title":"6. Run Python analysis","text":"<pre><code>analysis = client.analyze(\"Calculate descriptive statistics\", data_from=result)\nprint(analysis.summary)\n\n# Read or download output artifacts\nfor art in analysis.artifacts:\n    print(art.read_text())\n    art.download(\"./output/\")\n</code></pre>"},{"location":"getting-started/quickstart/#whats-next","title":"What's next?","text":"<ul> <li>Configuration \u2014 Customize settings, ports, and model</li> <li>Schema Documentation \u2014 Write better schema docs for more accurate queries</li> <li>Chaining Agents \u2014 Pipe results between query, analyze, and chart</li> <li>Client Reference \u2014 Full API reference for the Python SDK</li> </ul>"},{"location":"guides/chaining/","title":"Chaining Agents","text":"<p>One of the most powerful features of oneprompt is the ability to chain agents together. The output of one agent becomes the input for the next, enabling complex data workflows.</p>"},{"location":"guides/chaining/#how-chaining-works","title":"How Chaining Works","text":"<p>Every agent method (<code>query</code>, <code>analyze</code>, <code>chart</code>) returns an <code>AgentResult</code>. You can pass this result to the next agent using the <code>data_from</code> parameter:</p> <pre><code>import oneprompt as op\n\nclient = op.Client()\n\n# Step 1: Query data\ndata = client.query(\"Revenue by month for 2025\")\n\n# Step 2: Pass the result to the next agent\nchart = client.chart(\"Line chart of revenue trend\", data_from=data)\n</code></pre> <p>Under the hood, the SDK:</p> <ol> <li>Fetches the JSON artifact from the first result's Artifact Store URL</li> <li>Injects the data inline into the next agent's prompt</li> <li>The next agent processes it with full context</li> </ol>"},{"location":"guides/chaining/#common-patterns","title":"Common Patterns","text":""},{"location":"guides/chaining/#query-chart","title":"Query \u2192 Chart","text":"<p>Generate a visualization directly from query results:</p> <pre><code>data = client.query(\"Top 10 customers by total spend\")\nchart = client.chart(\"Horizontal bar chart of customer spending\", data_from=data)\nchart.artifacts[0].download(\"./output/\")\n</code></pre>"},{"location":"guides/chaining/#query-analyze","title":"Query \u2192 Analyze","text":"<p>Run statistical analysis on queried data:</p> <pre><code>data = client.query(\"All transactions this quarter\")\nstats = client.analyze(\"Calculate descriptive statistics per category\", data_from=data)\nprint(stats.summary)\n</code></pre>"},{"location":"guides/chaining/#query-analyze-chart","title":"Query \u2192 Analyze \u2192 Chart","text":"<p>The full pipeline \u2014 query data, process it, then visualize:</p> <pre><code># 1. Get raw data\ndata = client.query(\"Daily active users for the last 90 days\")\n\n# 2. Analyze it\ntrend = client.analyze(\"Calculate 7-day moving average\", data_from=data)\n\n# 3. Visualize the result\nchart = client.chart(\n    \"Line chart with original and smoothed data\",\n    data_from=trend\n)\n</code></pre>"},{"location":"guides/chaining/#analyze-chart","title":"Analyze \u2192 Chart","text":"<p>If you already have processed data, skip straight to charting:</p> <pre><code>data = client.query(\"Monthly revenue by region\")\nanalysis = client.analyze(\"Pivot data: months as rows, regions as columns\", data_from=data)\nchart = client.chart(\"Grouped bar chart of regional revenue\", data_from=analysis)\n</code></pre>"},{"location":"guides/chaining/#multiple-charts-from-one-query","title":"Multiple Charts from One Query","text":"<p>You can reuse a single query result to generate multiple visualizations:</p> <pre><code>data = client.query(\"Sales by product category and month\")\n\nbar = client.chart(\"Bar chart of total sales per category\", data_from=data)\nline = client.chart(\"Line chart of monthly sales trends\", data_from=data)\npie = client.chart(\"Pie chart of category distribution\", data_from=data)\n</code></pre>"},{"location":"guides/chaining/#how-data-flows-between-agents","title":"How Data Flows Between Agents","text":"<p>When you pass <code>data_from</code>, the SDK looks for data in this order:</p> <ol> <li>JSON artifact \u2014 Fetches the first <code>.json</code> artifact from the Artifact Store on demand</li> <li>Preview data \u2014 Falls back to <code>result.preview</code> (first rows returned by the query)</li> </ol> <p>This means the full dataset (not just the preview) is passed when a JSON artifact is available.</p>"},{"location":"guides/chaining/#rest-api-chaining","title":"REST API Chaining","text":"<p>You can achieve the same chaining via the REST API using artifact IDs:</p> <pre><code># 1. Query data\nDATA=$(curl -s -X POST http://localhost:8000/agents/data \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"query\": \"Monthly revenue for 2025\"}')\n\nARTIFACT_ID=$(echo $DATA | jq -r '.artifacts[0].id')\n\n# 2. Analyze\nANALYSIS=$(curl -s -X POST http://localhost:8000/agents/python \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\\\"instruction\\\": \\\"Calculate growth rate\\\", \\\"data_artifact_id\\\": \\\"$ARTIFACT_ID\\\"}\")\n\nRESULT_ID=$(echo $ANALYSIS | jq -r '.artifacts[0].id')\n\n# 3. Chart\ncurl -X POST http://localhost:8000/agents/chart \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\\\"question\\\": \\\"Line chart of revenue with growth\\\", \\\"data_artifact_id\\\": \\\"$RESULT_ID\\\"}\"\n</code></pre> <p>See the REST API Reference for full endpoint documentation.</p>"},{"location":"guides/configuration/","title":"Configuration","text":"<p>All settings can be provided via environment variables, a <code>.env</code> file, or directly when creating the <code>Client</code>.</p>"},{"location":"guides/configuration/#configuration-priority","title":"Configuration Priority","text":"<p>Settings are loaded in this order (later overrides earlier):</p> <ol> <li>Default values built into the SDK</li> <li><code>.env</code> file in the current working directory</li> <li>Environment variables set in your shell</li> <li>Arguments passed directly to <code>op.Client()</code> or <code>Config</code></li> </ol>"},{"location":"guides/configuration/#required-settings","title":"Required Settings","text":"<p>These settings are required in local mode (self-hosted with Docker):</p> Setting Env Variable Client Param Description LLM API Key <code>LLM_API_KEY</code> <code>llm_api_key</code> API key for your chosen LLM provider Database URL <code>DATABASE_URL</code> <code>database_url</code> PostgreSQL connection string, e.g. <code>postgresql://user:pass@host:5432/dbname</code>"},{"location":"guides/configuration/#cloud-mode-settings","title":"Cloud Mode Settings","text":"<p>When using cloud mode (<code>oneprompt-sdk</code>), the following are required instead:</p> Setting Env Variable Client Param Description oneprompt API Key <code>ONEPROMPT_API_KEY</code> <code>oneprompt_api_key</code> Your oneprompt cloud API key. Auto-loaded from credentials saved by <code>op login</code> oneprompt API URL <code>ONEPROMPT_API_URL</code> <code>oneprompt_api_url</code> Base URL of the oneprompt cloud API <p>The API key is resolved in this order:</p> <ol> <li><code>oneprompt_api_key</code> argument to <code>Client()</code> or <code>Config()</code></li> <li><code>ONEPROMPT_API_KEY</code> environment variable</li> <li>Credentials saved by <code>op login</code> (<code>~/.config/oneprompt/credentials</code>)</li> </ol> <p>The API URL is resolved in this order:</p> <ol> <li><code>oneprompt_api_url</code> argument to <code>Client()</code> or <code>Config()</code></li> <li><code>ONEPROMPT_API_URL</code> environment variable</li> </ol> <p>Neither has a built-in default \u2014 you must supply one of the above.</p> <pre><code># .env (cloud mode)\nONEPROMPT_API_KEY=op_live_...\nONEPROMPT_API_URL=https://api.oneprompt.eu\n</code></pre>"},{"location":"guides/configuration/#optional-settings","title":"Optional Settings","text":""},{"location":"guides/configuration/#llm-provider","title":"LLM Provider","text":"Env Variable Client Param Default Description <code>LLM_PROVIDER</code> <code>llm_provider</code> <code>google</code> LLM provider: <code>google</code>, <code>openai</code>, or <code>anthropic</code> <code>LLM_MODEL</code> <code>llm_model</code> provider default Model name (defaults: <code>gemini-3-flash-preview-preview</code>, <code>gpt-5</code>, <code>claude-sonnet-4.5</code>)"},{"location":"guides/configuration/#schema-documentation","title":"Schema Documentation","text":"Env Variable Client Param Default Description <code>OP_SCHEMA_DOCS_PATH</code> <code>schema_docs_path</code> <code>./DATABASE.md</code> Path to your database schema file <code>OP_SCHEMA_DOCS</code> <code>schema_docs</code> \u2014 Inline schema docs (alternative to file)"},{"location":"guides/configuration/#directories","title":"Directories","text":"Env Variable Client Param Default Description <code>OP_DATA_DIR</code> <code>data_dir</code> <code>./op_data</code> Directory for local data and state DB. Resolved to an absolute path at init time"},{"location":"guides/configuration/#network-ports","title":"Network Ports","text":"Env Variable Client Param Default Description <code>OP_PORT</code> <code>port</code> <code>8000</code> REST API server port <code>OP_ARTIFACT_PORT</code> <code>artifact_store_port</code> <code>3336</code> Artifact Store port <code>OP_POSTGRES_MCP_PORT</code> <code>postgres_mcp_port</code> <code>3333</code> PostgreSQL MCP server port <code>OP_CHART_MCP_PORT</code> <code>chart_mcp_port</code> <code>3334</code> Chart MCP server port <code>OP_PYTHON_MCP_PORT</code> <code>python_mcp_port</code> <code>3335</code> Python MCP server port"},{"location":"guides/configuration/#agent-behavior","title":"Agent Behavior","text":"Env Variable Client Param Default Description <code>OP_MAX_RECURSION</code> <code>agent_max_recursion</code> <code>10</code> Maximum iterations per agent invocation"},{"location":"guides/configuration/#internal","title":"Internal","text":"Env Variable Client Param Default Description <code>OP_ARTIFACT_TOKEN</code> <code>artifact_store_token</code> Auto-generated by <code>op start</code> Shared auth token between SDK and Artifact Store <code>OP_HOST</code> <code>host</code> <code>0.0.0.0</code> API server bind address"},{"location":"guides/configuration/#env-file-examples","title":".env File Examples","text":""},{"location":"guides/configuration/#local-mode","title":"Local mode","text":"<pre><code># LLM provider (google, openai, or anthropic)\nLLM_PROVIDER=google\nLLM_API_KEY=your-api-key-here\n\n# PostgreSQL connection string\n# If your DB runs locally and services start with `op start`, use host.docker.internal:\nDATABASE_URL=postgresql://user:password@host.docker.internal:5432/mydb\n\n# Optional\n# LLM_MODEL=gemini-3-flash-preview-preview\n# OP_SCHEMA_DOCS_PATH=./DATABASE.md\n# OP_DATA_DIR=./op_data\n# OP_PORT=8000\n# OP_ARTIFACT_PORT=3336\n# OP_POSTGRES_MCP_PORT=3333\n# OP_CHART_MCP_PORT=3334\n# OP_PYTHON_MCP_PORT=3335\n</code></pre>"},{"location":"guides/configuration/#cloud-mode","title":"Cloud mode","text":"<pre><code># oneprompt cloud credentials (required)\nONEPROMPT_API_KEY=op_live_...\nONEPROMPT_API_URL=https://api.oneprompt.eu\n\n# Default database for ephemeral queries (optional)\n# DATABASE_URL=postgresql://user:password@host:5432/mydb\n</code></pre>"},{"location":"guides/configuration/#using-the-config-object","title":"Using the Config Object","text":"<p>For advanced control, create a <code>Config</code> object explicitly:</p> <pre><code>from oneprompt import Client, Config\n\nconfig = Config(\n    llm_provider=\"google\",                # \"google\", \"openai\", or \"anthropic\"\n    llm_api_key=\"your-key\",\n    llm_model=\"gemini-3-flash-preview-preview\",   # optional, uses provider default if omitted\n    database_url=\"postgresql://user:pass@host.docker.internal:5432/mydb\",\n    schema_docs_path=\"./DATABASE.md\",\n    data_dir=\"./my_data\",\n)\n\nclient = Client(config=config)\n</code></pre> <p>Or load from environment:</p> <pre><code>from oneprompt import Config\n\nconfig = Config.from_env()\nprint(config.llm_model)          # gemini-3-flash-preview-preview\nprint(config.artifact_store_url) # http://localhost:3336\nprint(config.mcp_postgres_url)   # http://localhost:3333/mcp\n</code></pre>"},{"location":"guides/configuration/#computed-properties","title":"Computed Properties","text":"<p>The <code>Config</code> object provides these derived properties:</p> Property Value Description <code>artifact_store_url</code> <code>http://localhost:{artifact_store_port}</code> Full URL to artifact store <code>mcp_postgres_url</code> <code>http://localhost:{postgres_mcp_port}/mcp</code> Full URL to PostgreSQL MCP <code>mcp_chart_url</code> <code>http://localhost:{chart_mcp_port}/mcp</code> Full URL to Chart MCP <code>mcp_python_url</code> <code>http://localhost:{python_mcp_port}/mcp</code> Full URL to Python MCP <code>export_dir</code> <code>{data_dir}/exports</code> Directory for artifact file storage <code>state_db_path</code> <code>{data_dir}/state.db</code> Path to SQLite state database <code>mode</code> <code>\"cloud\"</code> or <code>\"local\"</code> Derived from whether <code>oneprompt_api_key</code> is set"},{"location":"guides/configuration/#validation","title":"Validation","text":"<p>The client validates required settings on initialization. If something is missing, you get a clear error:</p> <pre><code>client = op.Client()\n# ValueError: Configuration errors:\n#   - llm_api_key is required (env: LLM_API_KEY)\n#   - database_url is required (env: DATABASE_URL)\n</code></pre>"},{"location":"guides/configuration/#postgresql-connection-tips","title":"PostgreSQL Connection Tips","text":""},{"location":"guides/configuration/#local-database-accessed-from-docker-mcp-containers","title":"Local database accessed from Docker MCP containers","text":"<p>When <code>op start</code> is running, MCP servers run inside Docker. Use <code>host.docker.internal</code> to reach your local PostgreSQL:</p> <pre><code>DATABASE_URL=postgresql://user:password@host.docker.internal:5432/mydb\n</code></pre>"},{"location":"guides/configuration/#remote-database","title":"Remote database","text":"<pre><code>DATABASE_URL=postgresql://user:password@db.example.com:5432/mydb\n</code></pre>"},{"location":"guides/configuration/#special-characters-in-password","title":"Special characters in password","text":"<p>URL-encode special characters:</p> <pre><code>from urllib.parse import quote_plus\n\npassword = \"p@ss!word#123\"\nurl = f\"postgresql://user:{quote_plus(password)}@host.docker.internal:5432/db\"\n</code></pre>"},{"location":"guides/schema-docs/","title":"Schema Documentation","text":"<p>The <code>DATABASE.md</code> file provides context about your database to the AI agent. The more detail you include, the better the agent will understand your data and generate accurate SQL queries.</p>"},{"location":"guides/schema-docs/#why-schema-docs","title":"Why Schema Docs?","text":"<p>The AI agent needs to know:</p> <ul> <li>What tables exist and what they contain</li> <li>What columns are in each table and their types</li> <li>How tables are related (foreign keys)</li> <li>Any business rules or naming conventions</li> <li>Example queries that illustrate common patterns</li> </ul> <p>Without this context, the agent may guess table/column names incorrectly or write suboptimal SQL.</p>"},{"location":"guides/schema-docs/#quick-start","title":"Quick Start","text":"<p>Run <code>op init</code> to generate a template, then edit <code>DATABASE.md</code> in your project directory:</p> <pre><code>op init\n# Edit DATABASE.md with your actual schema\n</code></pre> <p>Point the client to it:</p> <pre><code>import oneprompt as op\n\n# Option A: Auto-detected from ./DATABASE.md\nclient = op.Client()\n\n# Option B: Explicit path\nclient = op.Client(schema_docs_path=\"./my_schema.md\")\n\n# Option C: Inline string\nclient = op.Client(schema_docs=\"# Schema\\n\\n## Tables\\n\\n### users\\n...\")\n</code></pre>"},{"location":"guides/schema-docs/#recommended-format","title":"Recommended Format","text":"<pre><code># Database Schema\n\n## Database Information\n- **Name:** myapp_production\n- **Version:** PostgreSQL 15\n- **Timezone:** UTC\n\n## Conventions\n- Primary keys: always `id` (integer or UUID)\n- Foreign keys: format `{table}_id`\n- Timestamps: `created_at`, `updated_at` (TIMESTAMPTZ)\n- Soft deletes: `deleted_at` column (NULL = active)\n\n## Tables\n\n### users\nRegistered application users.\n\n| Column | Type | Description |\n|--------|------|-------------|\n| id | integer | Primary key |\n| name | text | Full name |\n| email | text | Unique email address |\n| plan | text | Subscription plan: 'free', 'pro', 'enterprise' |\n| created_at | timestamptz | Registration date |\n\n### orders\nPurchase orders placed by users.\n\n| Column | Type | Description |\n|--------|------|-------------|\n| id | integer | Primary key |\n| user_id | integer | FK \u2192 users.id |\n| total | numeric(10,2) | Order total in USD |\n| status | text | 'pending', 'paid', 'shipped', 'delivered', 'cancelled' |\n| created_at | timestamptz | Order date |\n\n### order_items\nIndividual items within an order.\n\n| Column | Type | Description |\n|--------|------|-------------|\n| id | integer | Primary key |\n| order_id | integer | FK \u2192 orders.id |\n| product_id | integer | FK \u2192 products.id |\n| quantity | integer | Units ordered |\n| unit_price | numeric(10,2) | Price per unit at time of order |\n\n### products\nProduct catalog.\n\n| Column | Type | Description |\n|--------|------|-------------|\n| id | integer | Primary key |\n| name | text | Product name |\n| category | text | Product category |\n| price | numeric(10,2) | Current retail price in USD |\n| active | boolean | Whether the product is currently available |\n\n## Relationships\n- users.id \u2192 orders.user_id (one user has many orders)\n- orders.id \u2192 order_items.order_id (one order has many items)\n- products.id \u2192 order_items.product_id (one product in many order items)\n\n## Business Rules\n- Order totals should match the sum of (quantity \u00d7 unit_price) for all items\n- Only 'paid' and 'shipped' orders count as revenue\n- Products with active=false should not appear in new orders\n\n## Example Queries\n\n**Top 10 customers by total spend:**\n```sql\nSELECT u.name, SUM(o.total) as total_spend\nFROM users u\nJOIN orders o ON u.id = o.user_id\nWHERE o.status IN ('paid', 'shipped', 'delivered')\nGROUP BY u.name\nORDER BY total_spend DESC\nLIMIT 10;\n```\n</code></pre>"},{"location":"guides/schema-docs/#tips-for-better-results","title":"Tips for Better Results","text":""},{"location":"guides/schema-docs/#1-be-specific-about-column-values","title":"1. Be specific about column values","text":"<p>Instead of:</p> <pre><code>| status | text | Order status |\n</code></pre> <p>Write:</p> <pre><code>| status | text | 'pending', 'paid', 'shipped', 'delivered', 'cancelled' |\n</code></pre>"},{"location":"guides/schema-docs/#2-document-computed-relationships","title":"2. Document computed relationships","text":"<p>If certain queries require specific JOINs, show them:</p> <pre><code>## Notes\n- To get user names with order data, JOIN users ON users.id = orders.user_id\n- Revenue = SUM(total) WHERE status IN ('paid', 'shipped', 'delivered')\n</code></pre>"},{"location":"guides/schema-docs/#3-include-example-queries","title":"3. Include example queries","text":"<p>Example queries teach the AI agent your preferred query patterns:</p> <p><pre><code>## Example Queries\n\n**Active users in the last 30 days:**\n```sql\nSELECT DISTINCT u.name\nFROM users u\nJOIN orders o ON u.id = o.user_id\nWHERE o.created_at &gt;= CURRENT_DATE - INTERVAL '30 days';\n</code></pre> <pre><code>### 4. Note any quirks\n\n```markdown\n## Caveats\n- The `total` column in orders is stored in cents (divide by 100 for dollars)\n- Dates before 2023 use a different timezone convention\n- The `legacy_users` table is deprecated, use `users` instead\n</code></pre></p>"},{"location":"guides/schema-docs/#5-keep-it-updated","title":"5. Keep it updated","text":"<p>When your schema changes, update <code>DATABASE.md</code> accordingly. The AI agent can only work with the information you provide.</p>"},{"location":"reference/agent-result/","title":"AgentResult","text":"<p>Every SDK method (<code>query</code>, <code>chart</code>, <code>analyze</code>) returns an <code>AgentResult</code> object containing the operation's output, metadata, generated files, and execution metrics.</p> <pre><code>result = client.query(\"Top 10 products by revenue\")\n\nprint(result.ok)          # True\nprint(result.summary)     # \"Top 10 products by revenue\"\nprint(result.preview)     # [{\"product_name\": \"Widget Pro\", ...}, ...]\nprint(result.artifacts)   # [ArtifactRef(...), ...]\nprint(result.metrics)     # RunMetrics(duration_ms=4821.3, input_tokens=1240, ...)\n</code></pre>"},{"location":"reference/agent-result/#properties","title":"Properties","text":"Property Type Description <code>ok</code> <code>bool</code> Whether the operation succeeded <code>run_id</code> <code>str</code> Unique identifier for this execution <code>session_id</code> <code>str</code> Session this execution belongs to <code>summary</code> <code>str \\| None</code> Human-readable summary of the result <code>data</code> <code>dict</code> Agent-specific response fields (see below) <code>artifacts</code> <code>list[ArtifactRef]</code> Generated files (CSV, JSON, HTML) <code>metrics</code> <code>RunMetrics \\| None</code> Token usage and timing (local mode only) <code>error</code> <code>str \\| None</code> Error message if <code>ok</code> is <code>False</code>"},{"location":"reference/agent-result/#convenience-properties","title":"Convenience Properties","text":"Property Type Description <code>preview</code> <code>list[dict]</code> Preview rows from data queries. Shortcut for <code>data[\"preview\"]</code> <code>columns</code> <code>list[str]</code> Column names from data queries. Shortcut for <code>data[\"columns\"]</code>"},{"location":"reference/agent-result/#usage-examples","title":"Usage Examples","text":""},{"location":"reference/agent-result/#checking-success","title":"Checking success","text":"<pre><code>result = client.query(\"Revenue by month\")\n\nif result.ok:\n    print(result.summary)\n    for row in result.preview:\n        print(row)\nelse:\n    print(f\"Error: {result.error}\")\n</code></pre>"},{"location":"reference/agent-result/#accessing-preview-data","title":"Accessing preview data","text":"<pre><code>result = client.query(\"Top 5 customers\")\n\n# Column names\nprint(result.columns)  # [\"name\", \"total_spend\"]\n\n# Data rows\nfor row in result.preview:\n    print(f\"{row['name']}: ${row['total_spend']}\")\n</code></pre>"},{"location":"reference/agent-result/#working-with-artifacts","title":"Working with artifacts","text":"<pre><code>result = client.query(\"Monthly revenue\")\n\nfor artifact in result.artifacts:\n    print(f\"File: {artifact.name}\")\n    print(f\"Type: {artifact.type}\")\n\n# Read content on demand (fetched from the Artifact Store)\ncsv_text = result.artifacts[0].read_text()\n\n# Save to a local file\nresult.artifacts[0].download(\"./output/\")\n</code></pre>"},{"location":"reference/agent-result/#inspecting-execution-metrics","title":"Inspecting execution metrics","text":"<pre><code>result = client.query(\"Revenue by month\")\n\nm = result.metrics\nprint(f\"Ran in {m.duration_ms / 1000:.1f}s\")\nprint(f\"Tokens: {m.input_tokens} in / {m.output_tokens} out\")\nprint(f\"LLM calls: {m.llm_calls}\")\n</code></pre>"},{"location":"reference/agent-result/#error-handling","title":"Error handling","text":"<pre><code>result = client.query(\"Revenue from nonexistent_table\")\n\nif not result.ok:\n    print(f\"Failed: {result.error}\")\n    # \"Failed: Query failed: relation 'nonexistent_table' does not exist\"\n</code></pre>"},{"location":"reference/agent-result/#chaining-results","title":"Chaining results","text":"<pre><code>data = client.query(\"Sales by category\")\nchart = client.chart(\"Pie chart of category distribution\", data_from=data)\n</code></pre> <p>See Chaining Agents for more patterns.</p>"},{"location":"reference/agent-result/#agent-response-data","title":"Agent Response Data","text":"<p>The <code>data</code> property contains agent-specific fields. Redundant fields (<code>ok</code>, <code>error</code>, <code>artifacts</code>) and internal Docker paths are stripped automatically \u2014 only informative fields are kept.</p>"},{"location":"reference/agent-result/#data-agent","title":"Data Agent","text":"<pre><code>result.data = {\n    \"intent\": \"export\",           # \"preview\" or \"export\"\n    \"columns\": [\"name\", \"revenue\"],\n    \"preview\": [{\"name\": \"Widget\", \"revenue\": \"1000.00\"}],\n    \"row_count\": 10,              # None if not counted\n    \"format\": \"json\",\n}\n</code></pre>"},{"location":"reference/agent-result/#chart-agent","title":"Chart Agent","text":"<pre><code>result.data = {\n    \"tool\": \"chart_bar\",          # chart tool used\n    \"name\": \"bar_chart.json\",     # output file name\n}\n</code></pre>"},{"location":"reference/agent-result/#python-agent","title":"Python Agent","text":"<pre><code>result.data = {}  # summary is promoted to result.summary; artifacts to result.artifacts\n</code></pre>"},{"location":"reference/agent-result/#runmetrics","title":"RunMetrics","text":"<p><code>result.metrics</code> is a <code>RunMetrics</code> object populated in local mode. It accumulates token usage across all LLM calls made during the agent run.</p> <pre><code>from oneprompt import RunMetrics\n</code></pre>"},{"location":"reference/agent-result/#fields","title":"Fields","text":"Field Type Description <code>duration_ms</code> <code>float</code> Wall-clock time for the full agent run (milliseconds) <code>input_tokens</code> <code>int</code> Total input tokens sent to the LLM <code>output_tokens</code> <code>int</code> Total output tokens generated by the LLM <code>total_tokens</code> <code>int</code> Sum of input and output tokens <code>reasoning_tokens</code> <code>int \\| None</code> Thinking/reasoning tokens (models with extended thinking) <code>cached_tokens</code> <code>int \\| None</code> Tokens served from the provider's prompt cache <code>llm_calls</code> <code>int</code> Number of individual LLM roundtrips (one per agent step)"},{"location":"reference/agent-result/#example","title":"Example","text":"<pre><code>result = client.query(\"Summarize sales by region\")\n\nm = result.metrics\n# RunMetrics(duration_ms=6123.4, input_tokens=2100, output_tokens=418, total_tokens=2518, llm_calls=3)\n\nprint(f\"Duration:  {m.duration_ms / 1000:.1f}s\")\nprint(f\"Input:     {m.input_tokens} tokens\")\nprint(f\"Output:    {m.output_tokens} tokens\")\nprint(f\"Total:     {m.total_tokens} tokens\")\nif m.reasoning_tokens:\n    print(f\"Reasoning: {m.reasoning_tokens} tokens\")\nif m.cached_tokens:\n    print(f\"Cached:    {m.cached_tokens} tokens\")\nprint(f\"LLM calls: {m.llm_calls}\")\n</code></pre> <p>Cloud mode</p> <p><code>metrics</code> is <code>None</code> when using cloud mode (<code>oneprompt_api_key</code> is set), since agent execution happens server-side.</p>"},{"location":"reference/artifact-ref/","title":"ArtifactRef","text":"<p>An <code>ArtifactRef</code> represents a file generated by an agent execution (CSV data, JSON data, or HTML chart). Artifacts are stored in the Artifact Store and fetched on demand \u2014 nothing is downloaded until you ask for it.</p> <pre><code>result = client.query(\"Top products\")\n\nartifact = result.artifacts[0]\nprint(artifact.name)       # \"top_products.csv\"\nprint(artifact.read_text())  # fetch content from the Artifact Store\nartifact.download(\"./output/\")  # save to a local directory\n</code></pre>"},{"location":"reference/artifact-ref/#properties","title":"Properties","text":"Property Type Description <code>id</code> <code>str</code> Unique artifact identifier <code>name</code> <code>str</code> Filename (e.g. <code>top_products.csv</code>, <code>chart.html</code>) <code>type</code> <code>str \\| None</code> Artifact type: <code>\"data\"</code>, <code>\"result\"</code>, or <code>\"chart\"</code> <code>path</code> <code>str \\| None</code> Local file path (set after calling <code>download()</code>) <code>url</code> <code>str \\| None</code> Remote path in the Artifact Store"},{"location":"reference/artifact-ref/#methods","title":"Methods","text":""},{"location":"reference/artifact-ref/#read_text","title":"<code>read_text()</code>","text":"<p>Fetch the artifact content as a UTF-8 string. The result is cached in memory so subsequent calls are free.</p> <pre><code>read_text(encoding: str = \"utf-8\") -&gt; str\n</code></pre> <pre><code>csv_content = artifact.read_text()\nprint(csv_content)\n# product_name,total_revenue\n# Widget Pro,45230.00\n# Gadget X,38100.00\n</code></pre>"},{"location":"reference/artifact-ref/#read_bytes","title":"<code>read_bytes()</code>","text":"<p>Fetch the artifact content as raw bytes. Checks (in order): local file, memory cache, remote URL.</p> <pre><code>read_bytes() -&gt; bytes\n</code></pre> <pre><code>raw = artifact.read_bytes()\n</code></pre> <p>Note</p> <p>Raises <code>FileNotFoundError</code> if the artifact is not available locally and no download URL is set.</p>"},{"location":"reference/artifact-ref/#download","title":"<code>download()</code>","text":"<p>Download the artifact to a local file.</p> <pre><code>download(dest: str | Path = None) -&gt; Path\n</code></pre> Parameter Type Default Description <code>dest</code> <code>str \\| Path</code> <code>None</code> Destination path. See resolution rules below. Defaults to <code>&lt;cwd&gt;/&lt;artifact_name&gt;</code> <p>Destination resolution rules:</p> <code>dest</code> value Result <code>None</code> Saves in cwd using the artifact's original name Ends with <code>/</code> or <code>\\</code> Treated as a directory; artifact saved inside it with its original name (directory is created if needed) Existing directory path Same as above (original name preserved) Any other path Treated as an explicit file path <pre><code># Save to a directory \u2014 always use a trailing slash to ensure directory treatment\npath = artifact.download(\"./output/\")\n# \u2192 ./output/top_products.csv  (directory created if needed)\n\n# Save with an explicit filename\npath = artifact.download(\"./my_data.csv\")\n# \u2192 ./my_data.csv\n\n# Download all artifacts into a folder\nfor art in result.artifacts:\n    art.download(\"./output/\")\n# \u2192 ./output/visitas.csv, ./output/visitas.json, ...\n\n# Default: saves next to your script\npath = artifact.download()\n# \u2192 &lt;cwd&gt;/top_products.csv\n</code></pre> <p>After calling <code>download()</code>, the <code>path</code> property is set to the local file path.</p>"},{"location":"reference/artifact-ref/#artifact-types","title":"Artifact Types","text":"Type Generated By Typical Files <code>data</code> Data Agent (<code>query</code>) <code>.csv</code>, <code>.json</code> <code>result</code> Python Agent (<code>analyze</code>) <code>.csv</code>, <code>.json</code> <code>chart</code> Chart Agent (<code>chart</code>) <code>.html</code>"},{"location":"reference/artifact-ref/#how-it-works","title":"How It Works","text":"<p>Artifacts are stored in the Artifact Store (a Docker container). When you call <code>read_text()</code>, <code>read_bytes()</code>, or <code>download()</code>, the SDK fetches the content from the store via HTTP. The content is cached in memory so repeated reads don't trigger new network requests.</p> <pre><code>ArtifactRef.read_text()\n  \u2514\u2500\u2500 read_bytes()\n        \u251c\u2500\u2500 1. Local file? (path exists) \u2192 read from disk\n        \u251c\u2500\u2500 2. Memory cache? \u2192 return cached bytes\n        \u2514\u2500\u2500 3. Fetch from Artifact Store via HTTP \u2192 cache + return\n</code></pre>"},{"location":"reference/artifact-ref/#working-with-artifacts","title":"Working with Artifacts","text":""},{"location":"reference/artifact-ref/#read-as-pandas-dataframe","title":"Read as pandas DataFrame","text":"<pre><code>import pandas as pd\nimport io\n\nresult = client.query(\"All orders this month\")\ncsv_text = result.artifacts[0].read_text()\ndf = pd.read_csv(io.StringIO(csv_text))\n</code></pre>"},{"location":"reference/artifact-ref/#read-json-data","title":"Read JSON data","text":"<pre><code>import json\n\nresult = client.query(\"Revenue by category\")\njson_artifact = [a for a in result.artifacts if a.name.endswith(\".json\")][0]\ndata = json.loads(json_artifact.read_text())\n</code></pre>"},{"location":"reference/artifact-ref/#download-and-open-chart-in-browser","title":"Download and open chart in browser","text":"<pre><code>import webbrowser\n\nchart = client.chart(\"Bar chart of sales\", data_from=data)\npath = chart.artifacts[0].download(\"./output/\")\nwebbrowser.open(f\"file://{path.resolve()}\")\n</code></pre>"},{"location":"reference/artifact-ref/#download-all-artifacts","title":"Download all artifacts","text":"<pre><code>result = client.query(\"Monthly revenue\")\nfor art in result.artifacts:\n    local_path = art.download(\"./output/\")\n    print(f\"Saved: {local_path}\")\n</code></pre>"},{"location":"reference/cli/","title":"CLI","text":"<p>The <code>op</code> command-line tool manages your oneprompt project: scaffolding, starting/stopping services, and launching the API server.</p> <pre><code>op --help\n</code></pre>"},{"location":"reference/cli/#commands","title":"Commands","text":""},{"location":"reference/cli/#op-init","title":"<code>op init</code>","text":"<p>Initialize a new oneprompt project in the current directory.</p> <pre><code>op init [--dir TARGET_DIR] [--mode MODE]\n</code></pre> Option Default Description <code>--dir</code> <code>.</code> Target directory to initialize <code>--mode</code> interactive prompt <code>0</code>/<code>local</code> or <code>1</code>/<code>cloud</code> <p><code>op init</code> asks for mode if <code>--mode</code> is not provided.</p> <ul> <li><code>0</code> or <code>local</code>: local Docker mode</li> <li><code>1</code> or <code>cloud</code>: oneprompt cloud mode</li> </ul> <p>Creates mode-specific files:</p> File Purpose <code>DATABASE.md</code> Local mode only. Schema documentation template <code>docker-compose.yml</code> Local mode only. Docker stack for MCP servers <code>example.py</code> Ready-to-run example script <p>Note</p> <p>Existing files are not overwritten. In cloud mode, <code>op init</code> prompts for your oneprompt API key. The prompt is optional \u2014 press Enter to skip it if you already have <code>ONEPROMPT_API_KEY</code> set in your environment or <code>.env</code> file, or if you prefer to configure it later with <code>op login</code>.</p>"},{"location":"reference/cli/#op-start","title":"<code>op start</code>","text":"<p>Build and start all MCP servers and the Artifact Store via Docker Compose.</p> <pre><code>op start [OPTIONS]\n</code></pre> Option Env Variable Description <code>--schema</code> <code>OP_SCHEMA_DOCS_PATH</code> Path to DATABASE.md (default: <code>./DATABASE.md</code>) <code>-d / --detach</code> \u2014 Run in background (default: yes) <code>--no-detach</code> \u2014 Run in foreground <p>LLM credentials and the database URL are not required here \u2014 set them in your <code>Config</code> or <code>.env</code> file and they will be picked up by the SDK at runtime.</p> <p><code>op start</code> automatically generates a secure artifact store token and saves it to <code>op_data/.artifact_token</code> so the SDK can authenticate with the Artifact Store.</p> <p>Example:</p> <pre><code># Standard startup (DATABASE.md in current directory)\nop start\n\n# Point to a schema file in another location\nop start --schema /path/to/DATABASE.md\n\n# Run in foreground to see logs\nop start --no-detach\n</code></pre> <p>Services started:</p> Service Port Description Artifact Store 3336 File storage for generated outputs PostgreSQL MCP 3333 SQL query execution engine Chart MCP 3334 AntV chart generation Python MCP 3335 Sandboxed Python execution <p>Connecting to a local database</p> <p>If your PostgreSQL is running on your Mac/host machine, use <code>host.docker.internal</code> instead of <code>localhost</code> in your database URL: <pre><code>postgresql://user:pass@host.docker.internal:5432/mydb\n</code></pre></p>"},{"location":"reference/cli/#op-stop","title":"<code>op stop</code>","text":"<p>Stop all running Docker services.</p> <pre><code>op stop\n</code></pre>"},{"location":"reference/cli/#op-status","title":"<code>op status</code>","text":"<p>Show the status of all Docker services.</p> <pre><code>op status\n</code></pre> <p>Runs <code>docker compose ps</code> to display running containers and their ports.</p>"},{"location":"reference/cli/#op-logs","title":"<code>op logs</code>","text":"<p>Tail the Docker service logs.</p> <pre><code>op logs\n</code></pre> <p>Shows the last 50 lines and follows new output. Press <code>Ctrl+C</code> to stop.</p>"},{"location":"reference/cli/#op-api","title":"<code>op api</code>","text":"<p>Start the local REST API server.</p> <pre><code>op api [OPTIONS]\n</code></pre> Option Default Description <code>--host</code> <code>0.0.0.0</code> API server host <code>--port</code> <code>8000</code> API server port <code>--reload / --no-reload</code> <code>--reload</code> Auto-reload on code changes <p>Example:</p> <pre><code># Default settings\nop api\n\n# Custom port\nop api --port 9000\n\n# Production mode (no auto-reload)\nop api --no-reload\n</code></pre> <p>Prerequisite</p> <p>Run <code>op start</code> before <code>op api</code>. The API server depends on the MCP Docker services.</p>"},{"location":"reference/cli/#op-login","title":"<code>op login</code>","text":"<p>Save your oneprompt cloud API key for cloud mode.</p> <pre><code>op login [--api-key KEY]\n</code></pre>"},{"location":"reference/cli/#op-version","title":"<code>op --version</code>","text":"<p>Show the installed SDK version.</p> <pre><code>op --version\n</code></pre>"},{"location":"reference/cli/#typical-workflow","title":"Typical Workflow","text":"<pre><code># Local mode\nop init --mode local\n\n# 1. Edit DATABASE.md with your schema documentation\n\n# 2. Start services\nop start\n\n# 3. Verify everything is running\nop status\n\n# 4. Use the SDK or start the API\npython example.py    # Python SDK\nop api               # REST API\n\n# 5. View logs if needed\nop logs\n\n# 6. Stop when done\nop stop\n</code></pre> <pre><code># Cloud mode\nop init --mode cloud\n\n# `op init` optionally asks for your oneprompt API key (press Enter to skip).\n# Set ONEPROMPT_API_KEY and ONEPROMPT_API_URL in your .env file if not saved here.\n# No local Docker startup is needed.\npython example.py\n</code></pre>"},{"location":"reference/client/","title":"Client","text":"<p>The <code>Client</code> class is the main entry point for the oneprompt SDK. It orchestrates AI agents, manages sessions, and provides on-demand access to generated artifacts.</p> <pre><code>import oneprompt as op\n\nclient = op.Client()\n</code></pre>"},{"location":"reference/client/#constructor","title":"Constructor","text":"<pre><code>Client(\n    oneprompt_api_key: str = None,\n    oneprompt_api_url: str = None,\n    llm_api_key: str = None,\n    llm_provider: str = None,\n    llm_model: str = None,\n    database_url: str = None,\n    schema_docs: str = None,\n    schema_docs_path: str = None,\n    data_dir: str = None,\n    config: Config = None,\n    **kwargs\n)\n</code></pre>"},{"location":"reference/client/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>oneprompt_api_key</code> <code>str</code> <code>None</code> API key for cloud mode. Falls back to <code>ONEPROMPT_API_KEY</code> env var <code>oneprompt_api_url</code> <code>str</code> <code>None</code> Cloud API base URL. Falls back to <code>ONEPROMPT_API_URL</code> env var <code>llm_api_key</code> <code>str</code> <code>None</code> API key for the LLM provider. Falls back to <code>LLM_API_KEY</code> env var <code>llm_provider</code> <code>str</code> <code>None</code> LLM provider: <code>google</code>, <code>openai</code>, or <code>anthropic</code>. Falls back to <code>LLM_PROVIDER</code> env var <code>llm_model</code> <code>str</code> <code>None</code> Model name. Uses provider default if omitted <code>database_url</code> <code>str</code> <code>None</code> PostgreSQL connection string. Falls back to <code>DATABASE_URL</code> env var <code>schema_docs</code> <code>str</code> <code>None</code> Inline database schema documentation string <code>schema_docs_path</code> <code>str</code> <code>None</code> Path to a <code>DATABASE.md</code> file with schema docs <code>data_dir</code> <code>str</code> <code>None</code> Directory for local data and state storage. Defaults to <code>./op_data</code> relative to cwd. Resolved to an absolute path at init time <code>config</code> <code>Config</code> <code>None</code> Full <code>Config</code> object (overrides all individual params) <code>**kwargs</code> Additional config parameters passed to <code>Config</code>"},{"location":"reference/client/#initialization-options","title":"Initialization Options","text":"<pre><code>import oneprompt as op\n\n# Option A: Read from .env (recommended)\nclient = op.Client()\n\n# Option B: Pass credentials directly\nclient = op.Client(\n    llm_provider=\"google\",\n    llm_api_key=\"your-api-key\",\n    database_url=\"postgresql://user:pass@localhost:5432/mydb\",\n)\n\n# Option C: With schema docs\nclient = op.Client(\n    llm_api_key=\"your-api-key\",\n    database_url=\"postgresql://user:pass@localhost:5432/mydb\",\n    schema_docs_path=\"./DATABASE.md\",\n)\n\n# Option D: Custom output directory\nclient = op.Client(data_dir=\"./output\")\n\n# Option E: Full Config object\nfrom oneprompt import Config\n\nconfig = Config(\n    llm_provider=\"google\",\n    llm_api_key=\"your-api-key\",\n    llm_model=\"gemini-3-flash-preview\",\n    database_url=\"postgresql://...\",\n    schema_docs_path=\"./DATABASE.md\",\n    data_dir=\"./my_data\",\n)\nclient = op.Client(config=config)\n</code></pre>"},{"location":"reference/client/#validation","title":"Validation","text":"<p>The client validates required settings on initialization:</p> <pre><code>client = op.Client()\n# ValueError: Configuration errors:\n#   - llm_api_key is required (env: LLM_API_KEY)\n#   - database_url is required (env: DATABASE_URL)\n</code></pre>"},{"location":"reference/client/#methods","title":"Methods","text":""},{"location":"reference/client/#query","title":"<code>query()</code>","text":"<p>Query your PostgreSQL database using natural language.</p> <pre><code>query(\n    question: str,\n    session_id: str = None,\n    dataset_id: str = None,\n    database_url: str = None,\n    schema_docs: str = None,\n) -&gt; AgentResult\n</code></pre>"},{"location":"reference/client/#parameters_1","title":"Parameters","text":"Parameter Type Required Description <code>question</code> <code>str</code> \u2705 Natural language question about your data <code>session_id</code> <code>str</code> \u274c Session ID for grouping related runs. Auto-created if omitted <code>dataset_id</code> <code>str</code> \u274c Cloud mode only. Use a stored dataset by ID <code>database_url</code> <code>str</code> \u274c DSN override. In cloud mode this uses an ephemeral (non-persistent) dataset <code>schema_docs</code> <code>str</code> \u274c Optional schema docs override (used with <code>database_url</code>)"},{"location":"reference/client/#returns","title":"Returns","text":"<p><code>AgentResult</code> with:</p> <ul> <li><code>summary</code> \u2014 Human-readable description of the query result</li> <li><code>preview</code> \u2014 First rows of data as a list of dicts</li> <li><code>columns</code> \u2014 Column names from the result set</li> <li><code>artifacts</code> \u2014 CSV and JSON files with the full result</li> <li><code>metrics</code> \u2014 Token usage and timing (<code>RunMetrics</code>)</li> </ul>"},{"location":"reference/client/#example","title":"Example","text":"<pre><code>result = client.query(\"What are the top 10 products by revenue?\")\n\nprint(result.ok)        # True\nprint(result.summary)   # \"Top 10 products by revenue\"\nprint(result.columns)   # [\"product_name\", \"total_revenue\"]\nprint(result.preview)   # [{\"product_name\": \"Widget Pro\", \"total_revenue\": \"45230.00\"}, ...]\nprint(result.metrics)   # RunMetrics(duration_ms=5210.4, input_tokens=1840, ...)\n\n# Access the generated files\nfor artifact in result.artifacts:\n    print(artifact.name)                     # top_products.csv\n    print(artifact.read_text())              # fetch content on demand\n    artifact.download(\"./output/\")           # save locally\n</code></pre>"},{"location":"reference/client/#cloud-mode-dataset-selection","title":"Cloud Mode Dataset Selection","text":"<p>In cloud mode, each <code>query()</code> must choose exactly one dataset source:</p> <ol> <li> <p>Stored dataset: <pre><code>result = client.query(\n    \"Top 10 products by revenue\",\n    dataset_id=\"ds_123456\",\n)\n</code></pre></p> </li> <li> <p>Ephemeral dataset (no credential persistence): <pre><code>result = client.query(\n    \"Top 10 products by revenue\",\n    database_url=\"postgresql://user:pass@host:5432/db\",\n    schema_docs=\"# Optional inline schema docs\",\n)\n</code></pre></p> </li> </ol> <p>Rules:</p> <ul> <li><code>dataset_id</code> and <code>database_url</code> are mutually exclusive.</li> <li><code>schema_docs</code> with <code>dataset_id</code> is rejected in cloud mode.</li> <li>In local mode, <code>dataset_id</code> is ignored/rejected (no cloud dataset registry).</li> </ul>"},{"location":"reference/client/#how-it-works","title":"How It Works","text":"<ol> <li>The client creates a session (if needed) and generates a unique <code>run_id</code></li> <li>The Data Agent connects to the PostgreSQL MCP server</li> <li>Your <code>DATABASE.md</code> schema is passed as context to Gemini</li> <li>Gemini generates and executes a SQL query</li> <li>Results are exported to CSV and JSON, stored in the Artifact Store</li> <li>ArtifactRef objects are created with remote URLs for on-demand access</li> </ol>"},{"location":"reference/client/#chart","title":"<code>chart()</code>","text":"<p>Generate an interactive chart visualization using AntV G2Plot.</p> <pre><code>chart(\n    question: str,\n    data_from: AgentResult = None,\n    data_preview: str = None,\n    session_id: str = None,\n) -&gt; AgentResult\n</code></pre>"},{"location":"reference/client/#parameters_2","title":"Parameters","text":"Parameter Type Required Description <code>question</code> <code>str</code> \u2705 Description of the chart you want <code>data_from</code> <code>AgentResult</code> \u274c Previous result to use as data source <code>data_preview</code> <code>str</code> \u274c Raw data preview text (alternative to <code>data_from</code>) <code>session_id</code> <code>str</code> \u274c Session ID"},{"location":"reference/client/#returns_1","title":"Returns","text":"<p><code>AgentResult</code> with:</p> <ul> <li><code>summary</code> \u2014 Description of the generated chart</li> <li><code>artifacts</code> \u2014 HTML file containing the interactive chart</li> <li><code>metrics</code> \u2014 Token usage and timing (<code>RunMetrics</code>)</li> </ul>"},{"location":"reference/client/#example_1","title":"Example","text":"<pre><code># From a previous query\ndata = client.query(\"Revenue by month for 2025\")\nchart = client.chart(\"Line chart of monthly revenue\", data_from=data)\n\nprint(chart.ok)                     # True\nprint(chart.artifacts[0].name)      # \"line_chart.html\"\n\n# Read or download the chart\nprint(chart.artifacts[0].read_text())        # fetch HTML content\nchart.artifacts[0].download(\"./output/\")     # save locally\n\n# With inline data\nchart = client.chart(\n    \"Bar chart of sales\",\n    data_preview=\"product,sales\\nWidgets,100\\nGadgets,250\\nDoodads,75\"\n)\n</code></pre>"},{"location":"reference/client/#supported-chart-types","title":"Supported Chart Types","text":"<p>The Chart Agent can generate: bar, line, pie, scatter, area, column, grouped bar, stacked bar, dual-axis, and more. Just describe what you want and the agent will pick the right type.</p>"},{"location":"reference/client/#how-it-works_1","title":"How It Works","text":"<ol> <li>Data from <code>data_from</code> is fetched from the JSON artifact on demand (or <code>data_preview</code> is used)</li> <li>The Chart Agent connects to the Chart MCP server</li> <li>Gemini generates the chart configuration</li> <li>The MCP server creates an interactive HTML file with AntV G2Plot</li> <li>An ArtifactRef is returned for on-demand access</li> </ol>"},{"location":"reference/client/#analyze","title":"<code>analyze()</code>","text":"<p>Run Python analysis code in a sandboxed environment.</p> <pre><code>analyze(\n    instruction: str,\n    data_from: AgentResult = None,\n    output_name: str = \"result.csv\",\n    session_id: str = None,\n) -&gt; AgentResult\n</code></pre>"},{"location":"reference/client/#parameters_3","title":"Parameters","text":"Parameter Type Required Description <code>instruction</code> <code>str</code> \u2705 Description of the analysis to perform <code>data_from</code> <code>AgentResult</code> \u274c Previous result to use as input data <code>output_name</code> <code>str</code> \u274c Name for the output file (default: <code>result.csv</code>) <code>session_id</code> <code>str</code> \u274c Session ID"},{"location":"reference/client/#returns_2","title":"Returns","text":"<p><code>AgentResult</code> with:</p> <ul> <li><code>summary</code> \u2014 Description of the analysis performed</li> <li><code>artifacts</code> \u2014 Output files from the analysis</li> <li><code>metrics</code> \u2014 Token usage and timing (<code>RunMetrics</code>)</li> </ul>"},{"location":"reference/client/#example_2","title":"Example","text":"<pre><code>data = client.query(\"All transactions this year\")\n\n# Descriptive statistics\nstats = client.analyze(\n    \"Calculate mean, median, and standard deviation of order totals\",\n    data_from=data,\n)\nprint(stats.summary)\n\n# Custom output name\npivot = client.analyze(\n    \"Pivot table: months as rows, categories as columns, values = revenue\",\n    data_from=data,\n    output_name=\"pivot_table.csv\",\n)\nprint(pivot.artifacts[0].read_text())\npivot.artifacts[0].download(\"./output/\")\n</code></pre>"},{"location":"reference/client/#sandbox-environment","title":"Sandbox Environment","text":"<p>Python code runs in a secure Docker container with:</p> <ul> <li>Read-only filesystem</li> <li>Limited memory (2GB) and CPU (2 cores)</li> <li>No network access</li> <li>Pre-installed libraries: pandas, numpy, scipy, and standard library</li> </ul>"},{"location":"reference/client/#properties","title":"Properties","text":""},{"location":"reference/client/#config","title":"<code>config</code>","text":"<p>Access the current configuration:</p> <pre><code>client.config  # \u2192 Config object\nclient.config.llm_model        # \"gemini-3-flash-preview\"\nclient.config.database_url     # \"postgresql://...\"\nclient.config.data_dir         # \"/absolute/path/to/op_data\"\n</code></pre> <p>See Config for the full reference.</p>"},{"location":"reference/config/","title":"Config","text":"<p>The <code>Config</code> dataclass holds all oneprompt settings. It can be created from environment variables, a <code>.env</code> file, or direct initialization.</p> <pre><code>from oneprompt import Config\n\nconfig = Config.from_env()\n</code></pre>"},{"location":"reference/config/#constructor","title":"Constructor","text":"<pre><code>Config(\n    llm_provider: str = \"google\",\n    llm_api_key: str = \"\",\n    llm_model: str = \"\",\n    database_url: str = \"\",\n    schema_docs: str = \"\",\n    schema_docs_path: str = None,\n    data_dir: str = \"./op_data\",\n    host: str = \"0.0.0.0\",\n    port: int = 8000,\n    artifact_store_port: int = 3336,\n    postgres_mcp_port: int = 3333,\n    chart_mcp_port: int = 3334,\n    python_mcp_port: int = 3335,\n    artifact_store_token: str = \"\",\n    agent_max_recursion: int = 10,\n    # Cloud mode\n    oneprompt_api_key: str = \"\",\n    oneprompt_api_url: str = \"\",  # set via ONEPROMPT_API_URL env var\n)\n</code></pre>"},{"location":"reference/config/#parameters","title":"Parameters","text":"Parameter Type Default Env Variable Description <code>llm_provider</code> <code>str</code> <code>\"google\"</code> <code>LLM_PROVIDER</code> LLM provider: <code>google</code>, <code>openai</code>, or <code>anthropic</code> <code>llm_api_key</code> <code>str</code> <code>\"\"</code> <code>LLM_API_KEY</code> API key for the chosen LLM provider <code>llm_model</code> <code>str</code> <code>\"\"</code> <code>LLM_MODEL</code> Model name. If empty, uses provider default (<code>gemini-3-flash-preview-preview</code>, <code>gpt-5</code>, <code>claude-sonnet-4.5</code>) <code>database_url</code> <code>str</code> <code>\"\"</code> <code>DATABASE_URL</code> PostgreSQL connection string <code>schema_docs</code> <code>str</code> <code>\"\"</code> <code>OP_SCHEMA_DOCS</code> Inline schema documentation <code>schema_docs_path</code> <code>str</code> <code>None</code> <code>OP_SCHEMA_DOCS_PATH</code> Path to schema docs file <code>data_dir</code> <code>str</code> <code>./op_data</code> <code>OP_DATA_DIR</code> Local data directory <code>host</code> <code>str</code> <code>0.0.0.0</code> <code>OP_HOST</code> API server bind address <code>port</code> <code>int</code> <code>8000</code> <code>OP_PORT</code> API server port <code>artifact_store_port</code> <code>int</code> <code>3336</code> <code>OP_ARTIFACT_PORT</code> Artifact Store port <code>postgres_mcp_port</code> <code>int</code> <code>3333</code> <code>OP_POSTGRES_MCP_PORT</code> PostgreSQL MCP port <code>chart_mcp_port</code> <code>int</code> <code>3334</code> <code>OP_CHART_MCP_PORT</code> Chart MCP port <code>python_mcp_port</code> <code>int</code> <code>3335</code> <code>OP_PYTHON_MCP_PORT</code> Python MCP port <code>artifact_store_token</code> <code>str</code> <code>\"\"</code> <code>OP_ARTIFACT_TOKEN</code> Shared auth token (auto-loaded from <code>op_data/.artifact_token</code> if not set) <code>agent_max_recursion</code> <code>int</code> <code>10</code> <code>OP_MAX_RECURSION</code> Max agent iterations <code>oneprompt_api_key</code> <code>str</code> <code>\"\"</code> <code>ONEPROMPT_API_KEY</code> Cloud mode API key <code>oneprompt_api_url</code> <code>str</code> <code>\"\"</code> <code>ONEPROMPT_API_URL</code> Cloud API base URL (required in cloud mode)"},{"location":"reference/config/#class-methods","title":"Class Methods","text":""},{"location":"reference/config/#from_env","title":"<code>from_env()</code>","text":"<p>Create a <code>Config</code> from environment variables:</p> <pre><code>config = Config.from_env()\n</code></pre> <p>Reads all settings from the corresponding environment variables listed in the parameters table above.</p>"},{"location":"reference/config/#properties","title":"Properties","text":""},{"location":"reference/config/#mode","title":"<code>mode</code>","text":"<pre><code>config.mode  # \"local\" or \"cloud\"\n</code></pre> <p>Returns <code>\"cloud\"</code> if <code>oneprompt_api_key</code> is set, otherwise <code>\"local\"</code>.</p>"},{"location":"reference/config/#computed-properties","title":"Computed Properties","text":"Property Type Description <code>artifact_store_url</code> <code>str</code> <code>http://localhost:{artifact_store_port}</code> <code>mcp_postgres_url</code> <code>str</code> <code>http://localhost:{postgres_mcp_port}/mcp</code> <code>mcp_chart_url</code> <code>str</code> <code>http://localhost:{chart_mcp_port}/mcp</code> <code>mcp_python_url</code> <code>str</code> <code>http://localhost:{python_mcp_port}/mcp</code> <code>export_dir</code> <code>Path</code> <code>{data_dir}/exports</code> \u2014 used by Docker containers for artifact storage <code>state_db_path</code> <code>str</code> <code>{data_dir}/state.db</code> <pre><code>config = Config.from_env()\n\nprint(config.artifact_store_url)  # http://localhost:3336\nprint(config.mcp_postgres_url)    # http://localhost:3333/mcp\nprint(config.export_dir)          # /absolute/path/op_data/exports\nprint(config.state_db_path)       # /absolute/path/op_data/state.db\n</code></pre>"},{"location":"reference/config/#methods","title":"Methods","text":""},{"location":"reference/config/#validate","title":"<code>validate()</code>","text":"<p>Validate the configuration and return a list of errors:</p> <pre><code>validate() -&gt; list[str]\n</code></pre> <pre><code>config = Config()\nerrors = config.validate()\n# [\"llm_api_key is required (env: LLM_API_KEY)\",\n#  \"database_url is required (env: DATABASE_URL)\"]\n</code></pre>"},{"location":"reference/config/#to_env_dict","title":"<code>to_env_dict()</code>","text":"<p>Export configuration as an environment variables dictionary (used internally for Docker/subprocess):</p> <pre><code>to_env_dict() -&gt; dict[str, str]\n</code></pre> <pre><code>config = Config.from_env()\nenv = config.to_env_dict()\n# {\"LLM_API_KEY\": \"...\", \"DATABASE_URL\": \"...\", ...}\n</code></pre>"},{"location":"reference/config/#path-resolution","title":"Path Resolution","text":"<p>Relative paths in <code>data_dir</code> are resolved to absolute paths at initialization time, based on the current working directory.</p> <pre><code># If cwd is /home/user/project\nconfig = Config(data_dir=\"./op_data\")\nprint(config.data_dir)  # /home/user/project/op_data\n\n# Absolute paths are kept as-is\nconfig = Config(data_dir=\"/var/data/op\")\nprint(config.data_dir)  # /var/data/op\n</code></pre>"},{"location":"reference/config/#auto-loading-schema-docs","title":"Auto-loading Schema Docs","text":"<p>If <code>schema_docs_path</code> is provided and the file exists, the content is automatically loaded into <code>schema_docs</code> during initialization:</p> <pre><code>config = Config(\n    llm_api_key=\"...\",\n    database_url=\"...\",\n    schema_docs_path=\"./DATABASE.md\",\n)\n# config.schema_docs now contains the file content\n</code></pre>"},{"location":"reference/rest-api/","title":"REST API","text":"<p>The oneprompt local API server provides HTTP endpoints for integration with non-Python applications, frontends, or microservices.</p>"},{"location":"reference/rest-api/#starting-the-api","title":"Starting the API","text":"<pre><code>op api\n</code></pre> <p>Options:</p> <pre><code>op api --host 0.0.0.0 --port 8000     # Custom host/port\nop api --no-reload                      # Disable auto-reload\n</code></pre> <p>Prerequisite</p> <p>The MCP services must be running (<code>op start</code>) before starting the API.</p>"},{"location":"reference/rest-api/#endpoints","title":"Endpoints","text":"Method Endpoint Description <code>GET</code> <code>/health</code> Health check <code>POST</code> <code>/sessions</code> Create a new session <code>GET</code> <code>/sessions</code> List sessions <code>POST</code> <code>/agents/data</code> Run natural language data queries <code>POST</code> <code>/agents/python</code> Run Python analysis <code>POST</code> <code>/agents/chart</code> Generate chart visualizations <code>GET</code> <code>/runs/{run_id}/artifacts/{artifact_id}</code> Download an artifact"},{"location":"reference/rest-api/#health-check","title":"Health Check","text":"<p><code>GET /health</code></p> <p>Verify the API is running.</p> <pre><code>curl http://localhost:8000/health\n</code></pre> <p>Response:</p> <pre><code>{\n  \"status\": \"ok\"\n}\n</code></pre>"},{"location":"reference/rest-api/#sessions","title":"Sessions","text":"<p>Sessions group related runs and artifacts. A default session is created automatically when you make your first request without specifying a <code>session_id</code>.</p>"},{"location":"reference/rest-api/#create-a-session","title":"Create a session","text":"<p><code>POST /sessions</code></p> <pre><code>curl -X POST http://localhost:8000/sessions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"name\": \"Q1 Analysis\"}'\n</code></pre> <p>Response:</p> <pre><code>{\n  \"session_id\": \"abc123def456\",\n  \"name\": \"Q1 Analysis\",\n  \"created_at\": \"2026-02-10T10:30:00+00:00\",\n  \"status\": \"active\"\n}\n</code></pre>"},{"location":"reference/rest-api/#list-sessions","title":"List sessions","text":"<p><code>GET /sessions</code></p> <pre><code>curl http://localhost:8000/sessions\n</code></pre> <p>Response:</p> <pre><code>{\n  \"sessions\": [\n    {\n      \"session_id\": \"abc123def456\",\n      \"name\": \"Q1 Analysis\",\n      \"created_at\": \"2026-02-10T10:30:00+00:00\",\n      \"status\": \"active\"\n    }\n  ]\n}\n</code></pre>"},{"location":"reference/rest-api/#data-agent","title":"Data Agent","text":"<p>Query your PostgreSQL database using natural language.</p> <p><code>POST /agents/data</code></p>"},{"location":"reference/rest-api/#request-body","title":"Request Body","text":"Field Type Required Description <code>query</code> <code>string</code> \u2705 Natural language question about your data <code>session_id</code> <code>string</code> \u274c Session ID. Uses default session if omitted"},{"location":"reference/rest-api/#example","title":"Example","text":"<pre><code>curl -X POST http://localhost:8000/agents/data \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"query\": \"Show me the top 10 products by total revenue\"}'\n</code></pre>"},{"location":"reference/rest-api/#response","title":"Response","text":"<pre><code>{\n  \"run_id\": \"7c2978d9eb4e4536\",\n  \"session_id\": \"default_local_user\",\n  \"ok\": true,\n  \"summary\": \"Top 10 products by revenue\",\n  \"artifacts\": [\n    {\n      \"id\": \"cfd705a3ce20\",\n      \"type\": \"data\",\n      \"name\": \"top_products.csv\",\n      \"url\": \"/runs/7c2978d9eb4e4536/artifacts/cfd705a3ce20\"\n    },\n    {\n      \"id\": \"161b4c90aaf1\",\n      \"type\": \"data\",\n      \"name\": \"top_products.json\",\n      \"url\": \"/runs/7c2978d9eb4e4536/artifacts/161b4c90aaf1\"\n    }\n  ],\n  \"result\": {\n    \"ok\": true,\n    \"intent\": \"export\",\n    \"columns\": [\"product_name\", \"total_revenue\"],\n    \"preview\": [\n      {\"product_name\": \"Widget Pro\", \"total_revenue\": \"45230.00\"}\n    ],\n    \"row_count\": 10,\n    \"format\": \"json\"\n  }\n}\n</code></pre> <p>The agent automatically generates CSV and JSON files, and returns a preview of the first rows.</p>"},{"location":"reference/rest-api/#python-agent","title":"Python Agent","text":"<p>Run Python code for data analysis in a sandboxed environment.</p> <p><code>POST /agents/python</code></p>"},{"location":"reference/rest-api/#request-body_1","title":"Request Body","text":"Field Type Required Description <code>instruction</code> <code>string</code> \u2705 What analysis to perform <code>data_artifact_id</code> <code>string</code> \u274c Artifact ID from a previous run <code>output_name</code> <code>string</code> \u274c Output filename (default: <code>result.csv</code>) <code>session_id</code> <code>string</code> \u274c Session ID"},{"location":"reference/rest-api/#example_1","title":"Example","text":"<pre><code>curl -X POST http://localhost:8000/agents/python \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"instruction\": \"Calculate mean, median, and standard deviation of revenue\",\n    \"data_artifact_id\": \"cfd705a3ce20\"\n  }'\n</code></pre>"},{"location":"reference/rest-api/#response_1","title":"Response","text":"<pre><code>{\n  \"run_id\": \"8d3089e0fa12\",\n  \"session_id\": \"default_local_user\",\n  \"ok\": true,\n  \"summary\": \"Statistical analysis completed\",\n  \"artifacts\": [\n    {\n      \"id\": \"9f1234ab5678\",\n      \"type\": \"result\",\n      \"name\": \"result.csv\",\n      \"url\": \"/runs/8d3089e0fa12/artifacts/9f1234ab5678\"\n    }\n  ],\n  \"result\": {\n    \"ok\": true,\n    \"summary\": \"Descriptive statistics calculated successfully\"\n  }\n}\n</code></pre>"},{"location":"reference/rest-api/#chart-agent","title":"Chart Agent","text":"<p>Generate interactive AntV (G2Plot) chart visualizations.</p> <p><code>POST /agents/chart</code></p>"},{"location":"reference/rest-api/#request-body_2","title":"Request Body","text":"Field Type Required Description <code>question</code> <code>string</code> \u2705 Description of the chart to generate <code>data_artifact_id</code> <code>string</code> \u274c Artifact ID with the data to visualize <code>data_preview</code> <code>string</code> \u274c Inline data preview (CSV-like text) <code>session_id</code> <code>string</code> \u274c Session ID"},{"location":"reference/rest-api/#example_2","title":"Example","text":"<pre><code>curl -X POST http://localhost:8000/agents/chart \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"question\": \"Bar chart of products by revenue\",\n    \"data_artifact_id\": \"cfd705a3ce20\"\n  }'\n</code></pre>"},{"location":"reference/rest-api/#response_2","title":"Response","text":"<pre><code>{\n  \"run_id\": \"9e4190f1bc34\",\n  \"session_id\": \"default_local_user\",\n  \"ok\": true,\n  \"summary\": \"Chart generated\",\n  \"artifacts\": [\n    {\n      \"id\": \"a0345bcd9012\",\n      \"type\": \"chart\",\n      \"name\": \"bar_chart.html\",\n      \"url\": \"/runs/9e4190f1bc34/artifacts/a0345bcd9012\"\n    }\n  ],\n  \"result\": {\n    \"ok\": true,\n    \"name\": \"bar_chart.html\"\n  }\n}\n</code></pre> <p>The generated chart is an interactive HTML file using AntV G2Plot.</p>"},{"location":"reference/rest-api/#artifacts","title":"Artifacts","text":"<p>Download files generated by agent runs.</p> <p><code>GET /runs/{run_id}/artifacts/{artifact_id}</code></p> <pre><code>curl http://localhost:8000/runs/7c2978d9eb4e4536/artifacts/cfd705a3ce20 \\\n  -o top_products.csv\n</code></pre> <p>The response streams the file content. The <code>Content-Type</code> header matches the file type.</p>"},{"location":"reference/rest-api/#response-format","title":"Response Format","text":"<p>All agent endpoints return a consistent response structure:</p> <pre><code>{\n  \"run_id\": \"string\",\n  \"session_id\": \"string\",\n  \"ok\": true,\n  \"summary\": \"Human-readable description of the result\",\n  \"artifacts\": [\n    {\n      \"id\": \"string\",\n      \"type\": \"data | result | chart\",\n      \"name\": \"filename.ext\",\n      \"url\": \"/runs/{run_id}/artifacts/{artifact_id}\"\n    }\n  ],\n  \"result\": { }\n}\n</code></pre> Field Type Description <code>run_id</code> <code>string</code> Unique execution identifier <code>session_id</code> <code>string</code> Session this run belongs to <code>ok</code> <code>boolean</code> Whether the operation succeeded <code>summary</code> <code>string \\| null</code> Human-readable summary <code>artifacts</code> <code>array</code> List of generated files <code>result</code> <code>object</code> Agent-specific result details"},{"location":"reference/rest-api/#error-codes","title":"Error Codes","text":"HTTP Status Meaning <code>200</code> Success <code>400</code> Bad request (missing required fields) <code>404</code> Artifact or session not found <code>500</code> Internal server error (agent failure) <p>Error responses include details:</p> <pre><code>{\n  \"detail\": \"query field is required\"\n}\n</code></pre>"},{"location":"reference/rest-api/#chaining-via-api","title":"Chaining via API","text":"<p>You can pipe results between agents using artifact IDs:</p> <pre><code># 1. Query data\nDATA=$(curl -s -X POST http://localhost:8000/agents/data \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"query\": \"Monthly revenue for 2025\"}')\n\nARTIFACT_ID=$(echo $DATA | jq -r '.artifacts[0].id')\n\n# 2. Analyze with Python\nANALYSIS=$(curl -s -X POST http://localhost:8000/agents/python \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\\\"instruction\\\": \\\"Calculate growth rate\\\", \\\"data_artifact_id\\\": \\\"$ARTIFACT_ID\\\"}\")\n\nRESULT_ID=$(echo $ANALYSIS | jq -r '.artifacts[0].id')\n\n# 3. Generate chart\ncurl -X POST http://localhost:8000/agents/chart \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\\\"question\\\": \\\"Line chart of revenue with growth\\\", \\\"data_artifact_id\\\": \\\"$RESULT_ID\\\"}\"\n</code></pre>"}]}